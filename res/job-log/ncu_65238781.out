+ pwd
/home/xmei/projects/lstm
+ source /etc/profile.d/modules.sh
++++ /bin/ps -p 44074 -ocomm=
+++ /bin/basename slurm_script
++ shell=slurm_script
++ '[' -f /usr/share/Modules/init/slurm_script ']'
++ . /usr/share/Modules/init/sh
+++ MODULESHOME=/usr/share/Modules
+++ export MODULESHOME
+++ '[' python3/3.9.7:cuda/11.4.2 = '' ']'
+++ '[' /apps/modulefiles:/usr/share/Modules/modulefiles:/etc/modulefiles = '' ']'
+ module load python3
++ /usr/bin/modulecmd sh load python3
+ eval
+ pip3 install pandas numpy sklearn torch matplotlib
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: pandas in /u/home/xmei/.local/lib/python3.9/site-packages (1.5.0)
Requirement already satisfied: numpy in /u/home/xmei/.local/lib/python3.9/site-packages (1.23.3)
Requirement already satisfied: sklearn in /u/home/xmei/.local/lib/python3.9/site-packages (0.0)
Requirement already satisfied: torch in /u/home/xmei/.local/lib/python3.9/site-packages (1.12.1)
Requirement already satisfied: matplotlib in /u/home/xmei/.local/lib/python3.9/site-packages (3.6.0)
Requirement already satisfied: pytz>=2020.1 in /u/home/xmei/.local/lib/python3.9/site-packages (from pandas) (2022.2.1)
Requirement already satisfied: python-dateutil>=2.8.1 in /u/home/xmei/.local/lib/python3.9/site-packages (from pandas) (2.8.2)
Requirement already satisfied: scikit-learn in /u/home/xmei/.local/lib/python3.9/site-packages (from sklearn) (1.1.2)
Requirement already satisfied: typing-extensions in /u/home/xmei/.local/lib/python3.9/site-packages (from torch) (4.3.0)
Requirement already satisfied: pillow>=6.2.0 in /u/home/xmei/.local/lib/python3.9/site-packages (from matplotlib) (9.2.0)
Requirement already satisfied: contourpy>=1.0.1 in /u/home/xmei/.local/lib/python3.9/site-packages (from matplotlib) (1.0.5)
Requirement already satisfied: pyparsing>=2.2.1 in /u/home/xmei/.local/lib/python3.9/site-packages (from matplotlib) (3.0.9)
Requirement already satisfied: fonttools>=4.22.0 in /u/home/xmei/.local/lib/python3.9/site-packages (from matplotlib) (4.37.3)
Requirement already satisfied: cycler>=0.10 in /u/home/xmei/.local/lib/python3.9/site-packages (from matplotlib) (0.11.0)
Requirement already satisfied: packaging>=20.0 in /u/home/xmei/.local/lib/python3.9/site-packages (from matplotlib) (21.3)
Requirement already satisfied: kiwisolver>=1.0.1 in /u/home/xmei/.local/lib/python3.9/site-packages (from matplotlib) (1.4.4)
Requirement already satisfied: six>=1.5 in /u/home/xmei/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)
Requirement already satisfied: scipy>=1.3.2 in /u/home/xmei/.local/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.9.1)
Requirement already satisfied: joblib>=1.0.0 in /u/home/xmei/.local/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.2.0)
Requirement already satisfied: threadpoolctl>=2.0.0 in /u/home/xmei/.local/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.1.0)
WARNING: You are using pip version 21.2.3; however, version 22.2.2 is available.
You should consider upgrading via the '/apps/python3/3.9.7/bin/python3.9 -m pip install --upgrade pip' command.
+ env
SLURM_NODELIST=sciml1903
REMOTEHOST=login1.jlab.org
SLURM_LUSTRE_JOB_ID=sciml1903,xmei,65238781
SLURM_JOB_NAME=submit-job.slurm
MANPATH=/usr/man:/home/xmei/man:/apps/man:/usr/share/man:/usr/local/gnu/man:/usr/local/man:/usr/openwin/man:/usr/openwin/share/man:/usr/dt/share/man:/usr/dt/man:/opt/SUNWspro/man:/usr/X11R6/man:/opt/SUNWsdk/sdk_2.5/GL/man/:/opt/SUNWsdk/sdk_2.5/kcms/man/:/opt/SUNWsdk/sdk_2.5/xgl/man/:/opt/SUNWsdk/xil/doc/man/:/site/man:/usr/local/news/man:/opt/langtools/share/man:/opt/CC/share/man:/opt/ansic/share/man:/opt/aCC/share/man:/opt/fortran/share/man:/opt/fortran90/share/man:/opt/imake/man:/usr/contrib/man
XDG_SESSION_ID=68101
SLURMD_NODENAME=sciml1903
SLURM_TOPOLOGY_ADDR=sciml1903
HOSTNAME=sciml1903
SLURM_PRIO_PROCESS=0
SLURM_NODE_ALIASES=(null)
HOST=ifarm1802.jlab.org
TERM=xterm-256color
SHELL=/bin/tcsh
SLURM_JOB_QOS=normal
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
SSH_CLIENT=129.57.52.24 44773 22
OSNAME=Linux
QTDIR=/usr/lib64/qt-3.3
SLURM_JOB_GPUS=0
QTINC=/usr/lib64/qt-3.3/include
SSH_TTY=/dev/pts/133
OSVERS=3.10.0-1160.71.1.el7.x86_64
QT_GRAPHICSSYSTEM_CHECKED=1
ROCR_VISIBLE_DEVICES=0
SLURM_NNODES=1
GROUP=ITD
USER=xmei
LD_LIBRARY_PATH=/apps/cuda/11.4.2/lib64:/apps/python3/3.9.7/lib
LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:
OPENWINHOME=/usr/openwin
SLURM_JOBID=65238781
HOSTTYPE=x86_64-linux
COLUMNS=136
CEBAF_FTP=/site/ftp
SLURM_TASKS_PER_NODE=1
MAIL=/var/spool/mail/xmei
PATH=/apps/cuda/11.4.2/bin:/apps/python3/3.9.7/bin:/home/xmei/bin:/home/xmei/bin/Linux:/apps/bin:/site/bin:/usr/local/bin:/usr/sbin:/usr/bin/X11:/opt/SUNWspro/bin:/opt/ansic/bin:/opt/aCC/bin:/opt/fortran/bin:/opt/fortran90/bin:/opt/langtools/bin:/usr/ccs/bin:/usr/bin:/bin:/usr/dt/bin:/usr/openwin/bin:/etc:/usr/etc:/usr/xpg4/bin:/usr/ucb:/usr/bsd:/sbin:/usr/proc/bin:/opt/imake/bin:.
SLURM_WORKING_CLUSTER=scicomp:enpslurm21:6817:9216:101
SLURM_CONF=/etc/slurm/slurm.conf
SLURM_JOB_ID=65238781
SLURM_JOB_USER=xmei
PWD=/home/xmei/projects/lstm
CUDA_VISIBLE_DEVICES=0
_LMFILES_=/apps/modulefiles/python3/3.9.7:/apps/modulefiles/cuda/11.4.2
EDITOR=vi
MSH=-tcsh
LANG=en_US.UTF-8
MODULEPATH=/apps/modulefiles:/usr/share/Modules/modulefiles:/etc/modulefiles
SLURM_JOB_UID=11066
LOADEDMODULES=python3/3.9.7:cuda/11.4.2
KDEDIRS=/usr
SLURM_NODEID=0
SLURM_SUBMIT_DIR=/w/epsci-sciwork18/xmei/projects/lstm
SLURM_TASK_PID=44074
LINES=37
SLURM_CPUS_ON_NODE=1
SLURM_PROCID=0
ENVIRONMENT=BATCH
SLURM_JOB_NODELIST=sciml1903
PERL_HOMEDIR=0
SHLVL=2
HOME=/home/xmei
SLURM_LOCALID=0
OSTYPE=linux
SLURM_JOB_GID=761
SLURM_JOB_CPUS_PER_NODE=1
SLURM_CLUSTER_NAME=scicomp
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=ifarm1802.jlab.org
SLURM_JOB_PARTITION=gpu
VENDOR=unknown
MACHTYPE=x86_64
LOGNAME=xmei
VISUAL=vi
QTLIB=/usr/lib64/qt-3.3/lib
CVS_RSH=ssh
GPU_DEVICE_ORDINAL=0
SLURM_JOB_ACCOUNT=epsci
SSH_CONNECTION=129.57.52.24 44773 129.57.70.23 22
SLURM_JOB_NUM_NODES=1
MODULESHOME=/usr/share/Modules
LESSOPEN=||/usr/bin/lesspipe.sh %s
XDG_RUNTIME_DIR=/run/user/11066
OSREL=3.10.0-1160.71.1.el7.x86_64
QT_PLUGIN_PATH=/usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
SLURM_MEM_PER_NODE=24576
_=/usr/bin/env
+ srun python3 Simplified_LSTM.py
Using cuda device
Epoch    1: loss=0.009337, mse=0.000258, val_loss=0.009839, val_mse=0.000274, lr=0.0001
Epoch    2: loss=0.007841, mse=0.000226, val_loss=0.007962, val_mse=0.000229, lr=0.0001
Epoch    3: loss=0.007357, mse=0.000207, val_loss=0.007403, val_mse=0.000208, lr=0.0001
Epoch    4: loss=0.006544, mse=0.000169, val_loss=0.006631, val_mse=0.000175, lr=0.0001
Epoch    5: loss=0.006692, mse=0.000130, val_loss=0.006920, val_mse=0.000149, lr=0.0001
Epoch    6: loss=0.005252, mse=0.000102, val_loss=0.005663, val_mse=0.000126, lr=0.0001
Epoch    7: loss=0.005068, mse=0.000095, val_loss=0.004956, val_mse=0.000112, lr=0.0001
Epoch    8: loss=0.005002, mse=0.000090, val_loss=0.005419, val_mse=0.000114, lr=0.0001
Epoch    9: loss=0.005651, mse=0.000093, val_loss=0.005501, val_mse=0.000112, lr=0.0001
Epoch   10: loss=0.004509, mse=0.000081, val_loss=0.004873, val_mse=0.000103, lr=0.0001
Epoch   11: loss=0.005618, mse=0.000090, val_loss=0.005953, val_mse=0.000116, lr=0.0001
Epoch   12: loss=0.004304, mse=0.000077, val_loss=0.004514, val_mse=0.000097, lr=0.0001
Epoch   13: loss=0.004875, mse=0.000078, val_loss=0.005540, val_mse=0.000102, lr=0.0001
Epoch   14: loss=0.004096, mse=0.000072, val_loss=0.004709, val_mse=0.000097, lr=0.0001
Epoch   15: loss=0.004168, mse=0.000070, val_loss=0.004372, val_mse=0.000091, lr=0.0001
Epoch   16: loss=0.003905, mse=0.000067, val_loss=0.004469, val_mse=0.000089, lr=0.0001
Epoch   17: loss=0.004273, mse=0.000068, val_loss=0.004987, val_mse=0.000089, lr=0.0001
Epoch   18: loss=0.003602, mse=0.000059, val_loss=0.003873, val_mse=0.000078, lr=0.0001
Epoch   19: loss=0.003894, mse=0.000056, val_loss=0.004165, val_mse=0.000075, lr=0.0001
Epoch   20: loss=0.003414, mse=0.000047, val_loss=0.003698, val_mse=0.000063, lr=0.0001
Epoch   21: loss=0.003140, mse=0.000039, val_loss=0.003364, val_mse=0.000052, lr=0.0001
Epoch   22: loss=0.003070, mse=0.000034, val_loss=0.003363, val_mse=0.000043, lr=0.0001
Epoch   23: loss=0.003463, mse=0.000036, val_loss=0.003805, val_mse=0.000044, lr=0.0001
Epoch   24: loss=0.003035, mse=0.000031, val_loss=0.003361, val_mse=0.000038, lr=0.0001
Epoch   25: loss=0.002628, mse=0.000027, val_loss=0.002937, val_mse=0.000034, lr=0.0001
Epoch   26: loss=0.002524, mse=0.000026, val_loss=0.002905, val_mse=0.000032, lr=0.0001
Epoch   27: loss=0.002954, mse=0.000027, val_loss=0.003145, val_mse=0.000032, lr=0.0001
Epoch   28: loss=0.002966, mse=0.000027, val_loss=0.002851, val_mse=0.000030, lr=0.0001
Epoch   29: loss=0.002389, mse=0.000024, val_loss=0.002518, val_mse=0.000027, lr=0.0001
Epoch   30: loss=0.002271, mse=0.000023, val_loss=0.002830, val_mse=0.000028, lr=0.0001
Epoch   31: loss=0.003525, mse=0.000029, val_loss=0.003342, val_mse=0.000030, lr=0.0001
Epoch   32: loss=0.003158, mse=0.000027, val_loss=0.002746, val_mse=0.000026, lr=0.0001
Epoch   33: loss=0.002424, mse=0.000023, val_loss=0.002457, val_mse=0.000025, lr=0.0001
Epoch   34: loss=0.002782, mse=0.000024, val_loss=0.002686, val_mse=0.000026, lr=0.0001
Epoch   35: loss=0.002530, mse=0.000022, val_loss=0.002599, val_mse=0.000024, lr=0.0001
Epoch   36: loss=0.002138, mse=0.000020, val_loss=0.002302, val_mse=0.000022, lr=0.0001
Epoch   37: loss=0.002567, mse=0.000021, val_loss=0.002738, val_mse=0.000023, lr=0.0001
Epoch   38: loss=0.002879, mse=0.000024, val_loss=0.002527, val_mse=0.000021, lr=0.0001
Epoch   39: loss=0.002476, mse=0.000019, val_loss=0.002612, val_mse=0.000019, lr=0.0001
Epoch   40: loss=0.002311, mse=0.000017, val_loss=0.002771, val_mse=0.000017, lr=0.0001
Epoch   41: loss=0.002285, mse=0.000016, val_loss=0.002418, val_mse=0.000013, lr=0.0001
Epoch   42: loss=0.002229, mse=0.000015, val_loss=0.002165, val_mse=0.000010, lr=0.0001
Epoch   43: loss=0.001881, mse=0.000013, val_loss=0.001686, val_mse=0.000007, lr=0.0001
Epoch   44: loss=0.002284, mse=0.000016, val_loss=0.001977, val_mse=0.000008, lr=0.0001
Epoch   45: loss=0.002198, mse=0.000015, val_loss=0.001907, val_mse=0.000007, lr=0.0001
Epoch   46: loss=0.001580, mse=0.000011, val_loss=0.001616, val_mse=0.000006, lr=0.0001
Epoch   47: loss=0.001636, mse=0.000011, val_loss=0.001389, val_mse=0.000005, lr=0.0001
Epoch   48: loss=0.001910, mse=0.000012, val_loss=0.002059, val_mse=0.000008, lr=0.0001
Epoch   49: loss=0.001952, mse=0.000012, val_loss=0.002154, val_mse=0.000008, lr=0.0001
Epoch   50: loss=0.001695, mse=0.000011, val_loss=0.001516, val_mse=0.000005, lr=0.0001
Epoch   51: loss=0.001833, mse=0.000012, val_loss=0.001959, val_mse=0.000007, lr=0.0001
Epoch   52: loss=0.001977, mse=0.000012, val_loss=0.001828, val_mse=0.000006, lr=0.0001
Epoch   53: loss=0.001598, mse=0.000010, val_loss=0.001781, val_mse=0.000006, lr=0.0001
Epoch 00053: reducing learning rate of group 0 to 8.5000e-05.
Epoch   54: loss=0.001511, mse=0.000010, val_loss=0.001612, val_mse=0.000005, lr=8.5e-05
Epoch   55: loss=0.001344, mse=0.000009, val_loss=0.001346, val_mse=0.000004, lr=8.5e-05
Epoch   56: loss=0.001280, mse=0.000009, val_loss=0.001187, val_mse=0.000004, lr=8.5e-05
Epoch   57: loss=0.001411, mse=0.000010, val_loss=0.001289, val_mse=0.000004, lr=8.5e-05
Epoch   58: loss=0.001742, mse=0.000011, val_loss=0.001735, val_mse=0.000006, lr=8.5e-05
Epoch   59: loss=0.001519, mse=0.000010, val_loss=0.001371, val_mse=0.000004, lr=8.5e-05
Epoch   60: loss=0.001762, mse=0.000010, val_loss=0.001797, val_mse=0.000006, lr=8.5e-05
Epoch   61: loss=0.001320, mse=0.000009, val_loss=0.001145, val_mse=0.000003, lr=8.5e-05
Epoch   62: loss=0.001369, mse=0.000009, val_loss=0.001342, val_mse=0.000004, lr=8.5e-05
Epoch   63: loss=0.001406, mse=0.000009, val_loss=0.001567, val_mse=0.000004, lr=8.5e-05
Epoch   64: loss=0.001712, mse=0.000010, val_loss=0.001854, val_mse=0.000006, lr=8.5e-05
Epoch   65: loss=0.001341, mse=0.000009, val_loss=0.001346, val_mse=0.000004, lr=8.5e-05
Epoch   66: loss=0.001454, mse=0.000009, val_loss=0.001360, val_mse=0.000004, lr=8.5e-05
Epoch   67: loss=0.001354, mse=0.000009, val_loss=0.001367, val_mse=0.000004, lr=8.5e-05
Epoch 00067: reducing learning rate of group 0 to 7.2250e-05.
Epoch   68: loss=0.001455, mse=0.000009, val_loss=0.001374, val_mse=0.000004, lr=7.225000000000001e-05
Epoch   69: loss=0.001243, mse=0.000008, val_loss=0.001194, val_mse=0.000003, lr=7.225000000000001e-05
Epoch   70: loss=0.001245, mse=0.000008, val_loss=0.001220, val_mse=0.000003, lr=7.225000000000001e-05
Epoch   71: loss=0.001397, mse=0.000009, val_loss=0.001252, val_mse=0.000003, lr=7.225000000000001e-05
Epoch   72: loss=0.001290, mse=0.000009, val_loss=0.001271, val_mse=0.000003, lr=7.225000000000001e-05
Epoch   73: loss=0.001054, mse=0.000008, val_loss=0.000974, val_mse=0.000002, lr=7.225000000000001e-05
Epoch   74: loss=0.001388, mse=0.000009, val_loss=0.001391, val_mse=0.000004, lr=7.225000000000001e-05
Epoch   75: loss=0.001305, mse=0.000009, val_loss=0.001143, val_mse=0.000003, lr=7.225000000000001e-05
Epoch   76: loss=0.001604, mse=0.000010, val_loss=0.001279, val_mse=0.000003, lr=7.225000000000001e-05
Epoch   77: loss=0.001141, mse=0.000008, val_loss=0.001051, val_mse=0.000003, lr=7.225000000000001e-05
Epoch   78: loss=0.001069, mse=0.000008, val_loss=0.001125, val_mse=0.000003, lr=7.225000000000001e-05
Epoch   79: loss=0.001107, mse=0.000008, val_loss=0.001130, val_mse=0.000003, lr=7.225000000000001e-05
Epoch 00079: reducing learning rate of group 0 to 6.1413e-05.
Epoch   80: loss=0.000863, mse=0.000007, val_loss=0.000861, val_mse=0.000002, lr=6.141250000000001e-05
Epoch   81: loss=0.000966, mse=0.000008, val_loss=0.000900, val_mse=0.000002, lr=6.141250000000001e-05
Epoch   82: loss=0.000883, mse=0.000007, val_loss=0.000882, val_mse=0.000002, lr=6.141250000000001e-05
Epoch   83: loss=0.000937, mse=0.000007, val_loss=0.000933, val_mse=0.000002, lr=6.141250000000001e-05
Epoch   84: loss=0.000896, mse=0.000007, val_loss=0.000878, val_mse=0.000002, lr=6.141250000000001e-05
Epoch   85: loss=0.000946, mse=0.000007, val_loss=0.000948, val_mse=0.000002, lr=6.141250000000001e-05
Epoch   86: loss=0.000878, mse=0.000007, val_loss=0.000820, val_mse=0.000002, lr=6.141250000000001e-05
Epoch   87: loss=0.000819, mse=0.000007, val_loss=0.000827, val_mse=0.000002, lr=6.141250000000001e-05
Epoch   88: loss=0.001200, mse=0.000008, val_loss=0.001250, val_mse=0.000004, lr=6.141250000000001e-05
Epoch   89: loss=0.000975, mse=0.000007, val_loss=0.001023, val_mse=0.000002, lr=6.141250000000001e-05
Epoch   90: loss=0.001214, mse=0.000008, val_loss=0.000888, val_mse=0.000002, lr=6.141250000000001e-05
Epoch   91: loss=0.001217, mse=0.000008, val_loss=0.001232, val_mse=0.000003, lr=6.141250000000001e-05
Epoch   92: loss=0.000948, mse=0.000007, val_loss=0.001004, val_mse=0.000002, lr=6.141250000000001e-05
Epoch 00092: reducing learning rate of group 0 to 5.2201e-05.
Epoch   93: loss=0.001110, mse=0.000008, val_loss=0.000805, val_mse=0.000002, lr=5.2200625000000005e-05
Epoch   94: loss=0.001042, mse=0.000007, val_loss=0.001031, val_mse=0.000002, lr=5.2200625000000005e-05
Epoch   95: loss=0.000907, mse=0.000007, val_loss=0.000974, val_mse=0.000002, lr=5.2200625000000005e-05
Epoch   96: loss=0.001054, mse=0.000008, val_loss=0.000778, val_mse=0.000002, lr=5.2200625000000005e-05
Epoch   97: loss=0.001054, mse=0.000007, val_loss=0.001091, val_mse=0.000003, lr=5.2200625000000005e-05
Epoch   98: loss=0.000839, mse=0.000007, val_loss=0.000898, val_mse=0.000002, lr=5.2200625000000005e-05
Epoch   99: loss=0.001129, mse=0.000008, val_loss=0.000790, val_mse=0.000002, lr=5.2200625000000005e-05
Epoch  100: loss=0.000957, mse=0.000007, val_loss=0.000988, val_mse=0.000002, lr=5.2200625000000005e-05
