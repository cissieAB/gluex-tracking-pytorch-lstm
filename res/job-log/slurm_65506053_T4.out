+ pwd
/home/xmei/projects/gluex-tracking-pytorch-lstm/python
+ source /etc/profile.d/modules.sh
++++ /bin/ps -p 24839 -ocomm=
+++ /bin/basename slurm_script
++ shell=slurm_script
++ '[' -f /usr/share/Modules/init/slurm_script ']'
++ . /usr/share/Modules/init/sh
+++ MODULESHOME=/usr/share/Modules
+++ export MODULESHOME
+++ '[' python3/3.9.7 = '' ']'
+++ '[' /apps/modulefiles:/usr/share/Modules/modulefiles:/etc/modulefiles = '' ']'
+ module load python3
++ /usr/bin/modulecmd sh load python3
+ eval
+ pip3 install pandas numpy sklearn torch matplotlib
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: pandas in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (1.5.0)
Requirement already satisfied: numpy in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (1.23.3)
Requirement already satisfied: sklearn in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (0.0)
Requirement already satisfied: torch in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (1.12.1)
Requirement already satisfied: matplotlib in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (3.6.0)
Requirement already satisfied: pytz>=2020.1 in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from pandas) (2022.4)
Requirement already satisfied: python-dateutil>=2.8.1 in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from pandas) (2.8.2)
Requirement already satisfied: scikit-learn in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from sklearn) (1.1.2)
Requirement already satisfied: typing-extensions in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from torch) (4.3.0)
Requirement already satisfied: pyparsing>=2.2.1 in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from matplotlib) (3.0.9)
Requirement already satisfied: contourpy>=1.0.1 in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from matplotlib) (1.0.5)
Requirement already satisfied: pillow>=6.2.0 in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from matplotlib) (9.2.0)
Requirement already satisfied: packaging>=20.0 in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from matplotlib) (21.3)
Requirement already satisfied: cycler>=0.10 in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from matplotlib) (0.11.0)
Requirement already satisfied: fonttools>=4.22.0 in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from matplotlib) (4.37.4)
Requirement already satisfied: kiwisolver>=1.0.1 in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from matplotlib) (1.4.4)
Requirement already satisfied: six>=1.5 in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)
Requirement already satisfied: scipy>=1.3.2 in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.9.1)
Requirement already satisfied: threadpoolctl>=2.0.0 in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.1.0)
Requirement already satisfied: joblib>=1.0.0 in /w/epsci-sciwork18/xmei/jhub/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.2.0)
WARNING: You are using pip version 21.2.3; however, version 22.2.2 is available.
You should consider upgrading via the '/apps/python3/3.9.7/bin/python3.9 -m pip install --upgrade pip' command.
+ env
SLURM_NODELIST=sciml2103
REMOTEHOST=login1.jlab.org
SLURM_LUSTRE_JOB_ID=sciml2103,xmei,65506053
SLURM_JOB_NAME=torch-lstm-train
MANPATH=/usr/man:/home/xmei/man:/apps/man:/usr/share/man:/usr/local/gnu/man:/usr/local/man:/usr/openwin/man:/usr/openwin/share/man:/usr/dt/share/man:/usr/dt/man:/opt/SUNWspro/man:/usr/X11R6/man:/opt/SUNWsdk/sdk_2.5/GL/man/:/opt/SUNWsdk/sdk_2.5/kcms/man/:/opt/SUNWsdk/sdk_2.5/xgl/man/:/opt/SUNWsdk/xil/doc/man/:/site/man:/usr/local/news/man:/opt/langtools/share/man:/opt/CC/share/man:/opt/ansic/share/man:/opt/aCC/share/man:/opt/fortran/share/man:/opt/fortran90/share/man:/opt/imake/man:/usr/contrib/man
XDG_SESSION_ID=248790
SLURMD_NODENAME=sciml2103
SLURM_TOPOLOGY_ADDR=sciml2103
HOSTNAME=sciml2103
SLURM_PRIO_PROCESS=0
SLURM_NODE_ALIASES=(null)
HOST=ifarm1901.jlab.org
TERM=xterm-256color
SHELL=/bin/tcsh
SLURM_JOB_QOS=normal
TMPDIR=/tmp
SLURM_TOPOLOGY_ADDR_PATTERN=node
SSH_CLIENT=129.57.52.24 47528 22
OSNAME=Linux
QTDIR=/usr/lib64/qt-3.3
SLURM_JOB_GPUS=0
QTINC=/usr/lib64/qt-3.3/include
SSH_TTY=/dev/pts/139
OSVERS=3.10.0-1160.71.1.el7.x86_64
QT_GRAPHICSSYSTEM_CHECKED=1
ROCR_VISIBLE_DEVICES=0
SLURM_NNODES=1
GROUP=ITD
USER=xmei
LD_LIBRARY_PATH=/apps/python3/3.9.7/lib
LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:
OPENWINHOME=/usr/openwin
SLURM_JOBID=65506053
HOSTTYPE=x86_64-linux
COLUMNS=94
CEBAF_FTP=/site/ftp
SLURM_TASKS_PER_NODE=1
MAIL=/var/spool/mail/xmei
PATH=/apps/python3/3.9.7/bin:/home/xmei/bin:/home/xmei/bin/Linux:/apps/bin:/site/bin:/usr/local/bin:/usr/sbin:/usr/bin/X11:/opt/SUNWspro/bin:/opt/ansic/bin:/opt/aCC/bin:/opt/fortran/bin:/opt/fortran90/bin:/opt/langtools/bin:/usr/ccs/bin:/usr/bin:/bin:/usr/dt/bin:/usr/openwin/bin:/etc:/usr/etc:/usr/xpg4/bin:/usr/ucb:/usr/bsd:/sbin:/usr/proc/bin:/opt/imake/bin:.
SLURM_WORKING_CLUSTER=scicomp:enpslurm21:6817:9216:101
SLURM_CONF=/etc/slurm/slurm.conf
SLURM_JOB_ID=65506053
SLURM_JOB_USER=xmei
PWD=/home/xmei/projects/gluex-tracking-pytorch-lstm/python
CUDA_VISIBLE_DEVICES=0
_LMFILES_=/apps/modulefiles/python3/3.9.7
EDITOR=vi
MSH=-tcsh
LANG=en_US.UTF-8
MODULEPATH=/apps/modulefiles:/usr/share/Modules/modulefiles:/etc/modulefiles
SLURM_JOB_UID=11066
LOADEDMODULES=python3/3.9.7
KDEDIRS=/usr
SLURM_NODEID=0
SLURM_SUBMIT_DIR=/w/epsci-sciwork18/xmei/projects/gluex-tracking-pytorch-lstm/python
SLURM_TASK_PID=24839
LINES=37
SLURM_CPUS_ON_NODE=1
SLURM_PROCID=0
ENVIRONMENT=BATCH
SLURM_JOB_NODELIST=sciml2103
PERL_HOMEDIR=0
SHLVL=2
HOME=/home/xmei
SLURM_LOCALID=0
OSTYPE=linux
SLURM_JOB_GID=761
SLURM_JOB_CPUS_PER_NODE=1
SLURM_CLUSTER_NAME=scicomp
SLURM_GTIDS=0
SLURM_SUBMIT_HOST=ifarm1901.jlab.org
SLURM_JOB_PARTITION=gpu
VENDOR=unknown
MACHTYPE=x86_64
LOGNAME=xmei
VISUAL=vi
QTLIB=/usr/lib64/qt-3.3/lib
CVS_RSH=ssh
GPU_DEVICE_ORDINAL=0
SLURM_JOB_ACCOUNT=epsci
SSH_CONNECTION=129.57.52.24 47528 129.57.70.17 22
SLURM_JOB_NUM_NODES=1
MODULESHOME=/usr/share/Modules
LESSOPEN=||/usr/bin/lesspipe.sh %s
XDG_RUNTIME_DIR=/run/user/11066
OSREL=3.10.0-1160.71.1.el7.x86_64
QT_PLUGIN_PATH=/usr/lib64/kde4/plugins:/usr/lib/kde4/plugins
SLURM_MEM_PER_NODE=15360
_=/usr/bin/env
+ srun python3 Simplified_LSTM.py
Torch version 1.12.1+cu102
Training on cuda device
Epoch    1: loss=0.060380929969233485, mse=0.00026271381648257375, val_loss=0.009533607068717254, val_mse=0.0002900863764807582, lr=0.0001
Epoch    2: loss=0.008484748605880851, mse=0.0002235978899989277, val_loss=0.008279773033801925, val_mse=0.0002453123452141881, lr=0.0001
Epoch    3: loss=0.007615329573581267, mse=0.00020370919082779437, val_loss=0.007387143417493046, val_mse=0.00022525430540554225, lr=0.0001
Epoch    4: loss=0.007405183868715981, mse=0.00018818481476046145, val_loss=0.007388530413052897, val_mse=0.00021426206512842327, lr=0.0001
Epoch    5: loss=0.007398971438627033, mse=0.00017208258213941008, val_loss=0.006845826743456908, val_mse=0.00018538476433604956, lr=0.0001
Epoch    6: loss=0.00648337936155194, mse=0.00013158682850189507, val_loss=0.006218320706000364, val_mse=0.0001535808405606076, lr=0.0001
Epoch    7: loss=0.0059287077939470054, mse=0.00011125200398964807, val_loss=0.005887224604914661, val_mse=0.00013011238479521126, lr=0.0001
Epoch    8: loss=0.0056344175307465405, mse=9.959483577404171e-05, val_loss=0.0059311211973329765, val_mse=0.00012075012637069449, lr=0.0001
Epoch    9: loss=0.00558750011381186, mse=0.00010540031507844105, val_loss=0.006077830011707216, val_mse=0.0001224837760673836, lr=0.0001
Epoch   10: loss=0.005326376762462027, mse=8.91790768946521e-05, val_loss=0.005035469070805035, val_mse=0.00010446049418533221, lr=0.0001
Epoch   11: loss=0.004931531359876313, mse=8.604399772593752e-05, val_loss=0.0050591533902884095, val_mse=9.98034083750099e-05, lr=0.0001
Epoch   12: loss=0.00482759515262709, mse=8.312573481816798e-05, val_loss=0.004660517746048928, val_mse=9.668514394434169e-05, lr=0.0001
Epoch   13: loss=0.00504469989659353, mse=8.49458810989745e-05, val_loss=0.0052771989584845655, val_mse=9.811469499254599e-05, lr=0.0001
Epoch   14: loss=0.005193409925473384, mse=8.257861190941185e-05, val_loss=0.0052053224608174875, val_mse=9.932757529895753e-05, lr=0.0001
Epoch   15: loss=0.004962341788585388, mse=8.218152652261779e-05, val_loss=0.005079381376420071, val_mse=9.619619959266856e-05, lr=0.0001
Epoch   16: loss=0.004738044665032464, mse=7.901040953584015e-05, val_loss=0.004820005343502398, val_mse=9.25817948882468e-05, lr=0.0001
Epoch   17: loss=0.004848053858905282, mse=7.524202374042943e-05, val_loss=0.00453746216318639, val_mse=8.900435932446271e-05, lr=0.0001
Epoch   18: loss=0.004565415550703695, mse=8.115461969282478e-05, val_loss=0.004969299423633818, val_mse=9.225622488884255e-05, lr=0.0001
Epoch   19: loss=0.004614868208273814, mse=7.662490679649636e-05, val_loss=0.004979105527553375, val_mse=8.865765994414687e-05, lr=0.0001
Epoch   20: loss=0.004540031911355516, mse=6.80142329656519e-05, val_loss=0.004003349955828129, val_mse=8.127542241709307e-05, lr=0.0001
Epoch   21: loss=0.004304224480870419, mse=7.056962203932926e-05, val_loss=0.005376339905967749, val_mse=9.077177674043924e-05, lr=0.0001
Epoch   22: loss=0.0044330044949305305, mse=6.806020246585831e-05, val_loss=0.004314997487929446, val_mse=7.950576400617138e-05, lr=0.0001
Epoch   23: loss=0.00450925374603733, mse=6.256518827285618e-05, val_loss=0.004798150796308916, val_mse=8.203757897717878e-05, lr=0.0001
Epoch   24: loss=0.0042869979231812735, mse=5.893420166103169e-05, val_loss=0.004315302616243288, val_mse=7.457713945768774e-05, lr=0.0001
Epoch   25: loss=0.0040794826260470984, mse=5.4099342378322035e-05, val_loss=0.0040319533757971465, val_mse=7.033895963104442e-05, lr=0.0001
Epoch   26: loss=0.003931359468673867, mse=5.40087312401738e-05, val_loss=0.004379043769112574, val_mse=6.956892320886254e-05, lr=0.0001
Epoch 00026: reducing learning rate of group 0 to 8.5000e-05.
Epoch   27: loss=0.0037761743889990805, mse=4.567309588310309e-05, val_loss=0.00376252399269753, val_mse=5.915969086345285e-05, lr=8.5e-05
Epoch   28: loss=0.003350105878752983, mse=3.9793565520085394e-05, val_loss=0.0031419268697040754, val_mse=5.274199793348089e-05, lr=8.5e-05
Epoch   29: loss=0.0031970667430116623, mse=3.4247870644321665e-05, val_loss=0.0030432622159603257, val_mse=4.6482007746817544e-05, lr=8.5e-05
Epoch   30: loss=0.003100763587325288, mse=3.1077866879059e-05, val_loss=0.003077387961292148, val_mse=4.2332882003393024e-05, lr=8.5e-05
Epoch   31: loss=0.0031405525497183824, mse=2.8053596906829625e-05, val_loss=0.003202793126540573, val_mse=3.9131675293901935e-05, lr=8.5e-05
Epoch   32: loss=0.003102313625304633, mse=2.6191217330051586e-05, val_loss=0.0033978508021929913, val_mse=3.8931255403440446e-05, lr=8.5e-05
Epoch   33: loss=0.0028077843928165326, mse=2.1634677977999672e-05, val_loss=0.0028001170157431936, val_mse=3.3459629776189104e-05, lr=8.5e-05
Epoch   34: loss=0.0029534357338145277, mse=2.5871522666420788e-05, val_loss=0.003057585199022457, val_mse=3.299445961602032e-05, lr=8.5e-05
Epoch   35: loss=0.002720875414600861, mse=2.471033440087922e-05, val_loss=0.003174487504033651, val_mse=3.408604970900342e-05, lr=8.5e-05
Epoch   36: loss=0.0030346818598989307, mse=2.04878506337991e-05, val_loss=0.0029159602731204746, val_mse=3.15759280056227e-05, lr=8.5e-05
Epoch   37: loss=0.0027913040142644205, mse=2.1089554138598032e-05, val_loss=0.0026119291876041573, val_mse=2.9918423024355434e-05, lr=8.5e-05
Epoch   38: loss=0.0027836971768033132, mse=2.0120854969718494e-05, val_loss=0.0028522605570368963, val_mse=3.0840881663607433e-05, lr=8.5e-05
Epoch   39: loss=0.0027282995573776037, mse=1.8296874259249307e-05, val_loss=0.0025680765255126376, val_mse=2.9299810194061138e-05, lr=8.5e-05
Epoch   40: loss=0.0027731005260340897, mse=2.0135785234742798e-05, val_loss=0.0027097547952566418, val_mse=2.9071314202155918e-05, lr=8.5e-05
Epoch   41: loss=0.0024773263574827046, mse=1.809083369153086e-05, val_loss=0.002375625064631878, val_mse=2.767159094219096e-05, lr=8.5e-05
Epoch   42: loss=0.002586314589811482, mse=1.750509545672685e-05, val_loss=0.0021422741695199393, val_mse=2.6220457584713586e-05, lr=8.5e-05
Epoch   43: loss=0.0024125875492732214, mse=1.9938024706789292e-05, val_loss=0.002730200257579985, val_mse=2.871900869649835e-05, lr=8.5e-05
Epoch   44: loss=0.0024330303907055106, mse=1.917067311296705e-05, val_loss=0.0026828444455052236, val_mse=2.832994687196333e-05, lr=8.5e-05
Epoch   45: loss=0.0026774992733359674, mse=1.9941982827731408e-05, val_loss=0.0029061734128524273, val_mse=2.8452637707232498e-05, lr=8.5e-05
Epoch   46: loss=0.0025827458100278547, mse=1.8179409380536526e-05, val_loss=0.00257875178578315, val_mse=2.7163172489963472e-05, lr=8.5e-05
Epoch   47: loss=0.002483500997656055, mse=1.861559576354921e-05, val_loss=0.0024943539693393166, val_mse=2.617351674416568e-05, lr=8.5e-05
Epoch   48: loss=0.0026185010219447005, mse=1.9096843971055932e-05, val_loss=0.0025395013787827864, val_mse=2.5922538043232635e-05, lr=8.5e-05
Epoch 00048: reducing learning rate of group 0 to 7.2250e-05.
Epoch   49: loss=0.0021240804370923896, mse=1.6080683053587563e-05, val_loss=0.0023436766180547353, val_mse=2.4745098926359788e-05, lr=7.225000000000001e-05
Epoch   50: loss=0.0023675103368881764, mse=1.6202744518523104e-05, val_loss=0.0020706476791685826, val_mse=2.3644381144549698e-05, lr=7.225000000000001e-05
Epoch   51: loss=0.002054055979569483, mse=1.612607593415305e-05, val_loss=0.0023640049541938124, val_mse=2.448875966365449e-05, lr=7.225000000000001e-05
Epoch   52: loss=0.0021956999961483827, mse=1.6492871509399265e-05, val_loss=0.0021495680471412147, val_mse=2.3222630261443555e-05, lr=7.225000000000001e-05
Epoch   53: loss=0.002278432382122248, mse=1.6374769984395243e-05, val_loss=0.002108940062956068, val_mse=2.2865116989123635e-05, lr=7.225000000000001e-05
Epoch   54: loss=0.0022445096524098297, mse=1.5433177395607345e-05, val_loss=0.002068544977231471, val_mse=2.2130834622657858e-05, lr=7.225000000000001e-05
Epoch   55: loss=0.0019339059261504411, mse=1.4922151422069874e-05, val_loss=0.0020841890122066387, val_mse=2.168585342587903e-05, lr=7.225000000000001e-05
Epoch   56: loss=0.0020968494737459843, mse=1.4443182408285793e-05, val_loss=0.0021325450587621844, val_mse=2.1040443243691698e-05, lr=7.225000000000001e-05
Epoch   57: loss=0.0022423144063114433, mse=1.595751200511586e-05, val_loss=0.0024670664388050222, val_mse=2.2365280528902076e-05, lr=7.225000000000001e-05
Epoch   58: loss=0.002169979400769321, mse=1.5859586710575968e-05, val_loss=0.002709291264347633, val_mse=2.2586507839150727e-05, lr=7.225000000000001e-05
Epoch   59: loss=0.0022263413969894775, mse=1.283164328924613e-05, val_loss=0.002060501548625967, val_mse=1.8100357920047827e-05, lr=7.225000000000001e-05
Epoch   60: loss=0.002019386707888598, mse=1.2983107808395289e-05, val_loss=0.0024361972188121114, val_mse=1.9067179891862907e-05, lr=7.225000000000001e-05
Epoch   61: loss=0.0021358944817054734, mse=1.0539639333728701e-05, val_loss=0.002107586967007768, val_mse=1.5839179468457587e-05, lr=7.225000000000001e-05
Epoch   62: loss=0.0019089210081750093, mse=8.478150448354427e-06, val_loss=0.0017832758062407798, val_mse=1.2928227079100907e-05, lr=7.225000000000001e-05
Epoch   63: loss=0.0017082278978563775, mse=7.711025318712927e-06, val_loss=0.0018004770260357228, val_mse=1.0133025170944165e-05, lr=7.225000000000001e-05
Epoch   64: loss=0.001723836446094788, mse=5.433033493318362e-06, val_loss=0.0019079755246815973, val_mse=8.077130587480497e-06, lr=7.225000000000001e-05
Epoch   65: loss=0.0015240550039873318, mse=3.6358567285788013e-06, val_loss=0.00153296150839702, val_mse=5.5938335208338685e-06, lr=7.225000000000001e-05
Epoch   66: loss=0.0015111108923744432, mse=5.160199634701712e-06, val_loss=0.001687725916004738, val_mse=5.703653187083546e-06, lr=7.225000000000001e-05
Epoch   67: loss=0.0014591048359190533, mse=3.489322580207954e-06, val_loss=0.0016671785664173864, val_mse=5.198827693675412e-06, lr=7.225000000000001e-05
Epoch   68: loss=0.0015533985355245992, mse=2.23347706196364e-06, val_loss=0.0011552651934113628, val_mse=3.359587708473555e-06, lr=7.225000000000001e-05
Epoch   69: loss=0.001232076740684076, mse=2.962326789202052e-06, val_loss=0.0014510768650371785, val_mse=4.4198468458489515e-06, lr=7.225000000000001e-05
Epoch   70: loss=0.0014206413895358283, mse=4.704606453742599e-06, val_loss=0.00160827037000912, val_mse=5.047683771408629e-06, lr=7.225000000000001e-05
Epoch   71: loss=0.0014959461910807417, mse=3.0902626804163447e-06, val_loss=0.0014295294135102058, val_mse=4.272745627531549e-06, lr=7.225000000000001e-05
Epoch   72: loss=0.0011684796140013188, mse=2.93918719762587e-06, val_loss=0.0012916655620326778, val_mse=3.6013586850458523e-06, lr=7.225000000000001e-05
Epoch   73: loss=0.0011605240196792366, mse=2.6454517865204252e-06, val_loss=0.0013185211972455428, val_mse=3.5321763789397664e-06, lr=7.225000000000001e-05
Epoch   74: loss=0.0013805752235400248, mse=2.853595788110397e-06, val_loss=0.0016480091158689425, val_mse=4.9481964197184425e-06, lr=7.225000000000001e-05
Epoch 00074: reducing learning rate of group 0 to 6.1413e-05.
Epoch   75: loss=0.0010723142429448016, mse=2.380116256972542e-06, val_loss=0.0013030669057699348, val_mse=3.713910700753331e-06, lr=6.141250000000001e-05
Epoch   76: loss=0.0013869915819599646, mse=2.56956764133065e-06, val_loss=0.0012087030376023145, val_mse=3.1144384138315218e-06, lr=6.141250000000001e-05
Epoch   77: loss=0.001270330023696245, mse=1.7464016082158196e-06, val_loss=0.0010552903574553851, val_mse=2.6531324692768976e-06, lr=6.141250000000001e-05
Epoch   78: loss=0.0012930182268632315, mse=3.4431386666256003e-06, val_loss=0.0017819772662234403, val_mse=5.27839665664942e-06, lr=6.141250000000001e-05
Epoch   79: loss=0.0012546257765959697, mse=2.951131818917929e-06, val_loss=0.0013342685891453185, val_mse=3.5424209272605367e-06, lr=6.141250000000001e-05
Epoch   80: loss=0.0011576733681588898, mse=1.788522695278516e-06, val_loss=0.001204776432298025, val_mse=3.129016249658889e-06, lr=6.141250000000001e-05
Epoch   81: loss=0.0012552614161818495, mse=2.2268038719630567e-06, val_loss=0.0012199410793603004, val_mse=3.115052095381543e-06, lr=6.141250000000001e-05
Epoch   82: loss=0.0012883686368769843, mse=2.0880315787508152e-06, val_loss=0.001185011054367972, val_mse=3.0637431791546987e-06, lr=6.141250000000001e-05
Epoch   83: loss=0.001102973386215442, mse=1.7501188267488033e-06, val_loss=0.0010152568230387777, val_mse=2.6041761884698644e-06, lr=6.141250000000001e-05
Epoch   84: loss=0.0012526518252001814, mse=2.163247017961112e-06, val_loss=0.0011446955337664519, val_mse=2.8754054710589116e-06, lr=6.141250000000001e-05
Epoch   85: loss=0.001211733811983814, mse=1.7823040252551436e-06, val_loss=0.0010253134618983366, val_mse=2.5597496460250113e-06, lr=6.141250000000001e-05
Epoch   86: loss=0.0011277101897562553, mse=1.8898859934779466e-06, val_loss=0.001152750492569561, val_mse=2.8355880203889683e-06, lr=6.141250000000001e-05
Epoch   87: loss=0.0010007305649079143, mse=1.7028983165801037e-06, val_loss=0.0010653319982882497, val_mse=2.6519535367697245e-06, lr=6.141250000000001e-05
Epoch   88: loss=0.0009732803558624585, mse=1.6957379784798832e-06, val_loss=0.0010894034928209245, val_mse=2.6894722395809367e-06, lr=6.141250000000001e-05
Epoch   89: loss=0.0010987643247021388, mse=3.1229046726366505e-06, val_loss=0.0013250913378204691, val_mse=3.2872508199943695e-06, lr=6.141250000000001e-05
Epoch 00089: reducing learning rate of group 0 to 5.2201e-05.
Epoch   90: loss=0.0009524874566500632, mse=1.3660641116075567e-06, val_loss=0.0009204258022748598, val_mse=2.238628894701833e-06, lr=5.2200625000000005e-05
Epoch   91: loss=0.0009122473836699289, mse=1.2577443158079404e-06, val_loss=0.0008943463657784719, val_mse=2.1458190531120636e-06, lr=5.2200625000000005e-05
Epoch   92: loss=0.0009058498396338061, mse=1.538269430056971e-06, val_loss=0.0010224965266685444, val_mse=2.4809528440528084e-06, lr=5.2200625000000005e-05
Epoch   93: loss=0.0008981722989450942, mse=1.2323463352004183e-06, val_loss=0.0008674044979593065, val_mse=2.07011794373102e-06, lr=5.2200625000000005e-05
Epoch   94: loss=0.0010150242797885465, mse=1.5669174899812788e-06, val_loss=0.0010469869341156967, val_mse=2.461710437273723e-06, lr=5.2200625000000005e-05
Epoch   95: loss=0.0011371289594114388, mse=1.9753138076339383e-06, val_loss=0.0012664837081010048, val_mse=3.0382034310605377e-06, lr=5.2200625000000005e-05
Epoch   96: loss=0.001020345707594963, mse=1.7046278344423627e-06, val_loss=0.001227344827641657, val_mse=2.954037199742743e-06, lr=5.2200625000000005e-05
Epoch   97: loss=0.0010435457389253461, mse=1.7616461036595865e-06, val_loss=0.0009918211614916303, val_mse=2.3590032469655853e-06, lr=5.2200625000000005e-05
Epoch   98: loss=0.001045480190376014, mse=1.115006625695969e-06, val_loss=0.0009869821169731724, val_mse=2.352231604163535e-06, lr=5.2200625000000005e-05
Epoch   99: loss=0.0008546058494172216, mse=1.1899177252416848e-06, val_loss=0.0008524005170743665, val_mse=2.012689719776972e-06, lr=5.2200625000000005e-05
Epoch  100: loss=0.0010561184952984541, mse=1.7272984678129433e-06, val_loss=0.0009713079839983719, val_mse=2.3378338482871186e-06, lr=5.2200625000000005e-05

#########################################
LSTMNetwork(
  (layer_lstm1): LSTM(6, 128, batch_first=True)
  (layer_lstm2): LSTM(128, 64, batch_first=True)
  (layer_lstm3): LSTM(64, 32, batch_first=True)
  (layer_output): Linear(in_features=32, out_features=6, bias=True)
)
Model's state_dict:
	 layer_lstm1.weight_ih_l0 	 torch.Size([512, 6])
	 layer_lstm1.weight_hh_l0 	 torch.Size([512, 128])
	 layer_lstm1.bias_ih_l0 	 torch.Size([512])
	 layer_lstm1.bias_hh_l0 	 torch.Size([512])
	 layer_lstm2.weight_ih_l0 	 torch.Size([256, 128])
	 layer_lstm2.weight_hh_l0 	 torch.Size([256, 64])
	 layer_lstm2.bias_ih_l0 	 torch.Size([256])
	 layer_lstm2.bias_hh_l0 	 torch.Size([256])
	 layer_lstm3.weight_ih_l0 	 torch.Size([128, 64])
	 layer_lstm3.weight_hh_l0 	 torch.Size([128, 32])
	 layer_lstm3.bias_ih_l0 	 torch.Size([128])
	 layer_lstm3.bias_hh_l0 	 torch.Size([128])
	 layer_output.weight 	 torch.Size([6, 32])
	 layer_output.bias 	 torch.Size([6])

#########################################
Traceback (most recent call last):
  File "/w/epsci-sciwork18/xmei/projects/gluex-tracking-pytorch-lstm/python/Simplified_LSTM.py", line 194, in <module>
    
  File "/home/xmei/.local/lib/python3.9/site-packages/torch/jit/_script.py", line 1286, in script
    return torch.jit._recursive.create_script_module(
  File "/home/xmei/.local/lib/python3.9/site-packages/torch/jit/_recursive.py", line 458, in create_script_module
    return create_script_module_impl(nn_module, concrete_type, stubs_fn)
  File "/home/xmei/.local/lib/python3.9/site-packages/torch/jit/_recursive.py", line 524, in create_script_module_impl
    create_methods_and_properties_from_stubs(concrete_type, method_stubs, property_stubs)
  File "/home/xmei/.local/lib/python3.9/site-packages/torch/jit/_recursive.py", line 375, in create_methods_and_properties_from_stubs
    concrete_type._create_methods_and_properties(property_defs, property_rcbs, method_defs, method_rcbs, method_defaults)
RuntimeError: 
Python type cannot be used as a value:
  File "/w/epsci-sciwork18/xmei/projects/gluex-tracking-pytorch-lstm/python/Simplified_LSTM.py", line 50
    def __init__(self, data_dim, hidden_dim):
        super(LSTMNetwork, self).__init__()
              ~~~~~~~~~~~ <--- HERE
    
        self.hidden_size = hidden_dim

srun: error: sciml2103: task 0: Exited with exit code 1


^^^^^^^^^^^^^^^^^^^^^^
The above error does not influence saving the model
